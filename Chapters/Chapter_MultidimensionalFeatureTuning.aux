\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}\color  {thesisBlue} Using Generative Models of Natural Images to Define Neural Tuning Manifolds}{59}{chapter.112}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:maps}{{4}{59}{\color {thesisBlue} Using Generative Models of Natural Images to Define Neural Tuning Manifolds}{chapter.112}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Introduction}{59}{section.113}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Methods}{61}{section.114}\protected@file@percent }
\newlabel{methods:gan}{{4.2}{67}{Generative Adversarial Network}{section*.127}{}}
\newlabel{globalPart}{{4.6}{69}{Particle Swarm}{equation.135}{}}
\newlabel{methods:relativeLinearity}{{4.2}{70}{Relative Linearity}{section*.142}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Results}{71}{section.144}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces {\it  Example GAN Stimuli.} Four example images generated by the 128 GAN latents (top row) and their pixel reconstruction after dimensionality reduction with PCA (bottom row).\relax }}{72}{figure.caption.145}\protected@file@percent }
\newlabel{fig:exampleReconstructions}{{4.1}{72}{{\it Example GAN Stimuli.} Four example images generated by the 128 GAN latents (top row) and their pixel reconstruction after dimensionality reduction with PCA (bottom row).\relax }{figure.caption.145}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces {\it  Individual neuron model fits} A.) AIC for GLMs using the GAN latents as predictors (x-axis) and the pixel predictors (y-axis) on neuron spike counts. B.) Relative change in AIC across models for individual neurons. Negative values indicate that the GAN latents are better predictors of neural data while positive values indicate that the pixel model was better. The latent model was better on average in both brain regions (V1: $t=-10.26$, $p=1.54 \cdot 10^{-23}$, V4: $t=-6.02$, $p=3.46\cdot 10^{-9}$; t-test).\relax }}{73}{figure.caption.146}\protected@file@percent }
\newlabel{fig:modelAICs}{{4.2}{73}{{\it Individual neuron model fits} A.) AIC for GLMs using the GAN latents as predictors (x-axis) and the pixel predictors (y-axis) on neuron spike counts. B.) Relative change in AIC across models for individual neurons. Negative values indicate that the GAN latents are better predictors of neural data while positive values indicate that the pixel model was better. The latent model was better on average in both brain regions (V1: $t=-10.26$, $p=1.54 \cdot 10^{-23}$, V4: $t=-6.02$, $p=3.46\cdot 10^{-9}$; t-test).\relax }{figure.caption.146}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces {\it  Canonical Correlations in neural data} A.) Simulated stimulus data where points were randomly selected to span an arbitrary space. The red line indicates the axis chosen by CCA for panel D. B.) Neural state space of stimuli from panel A (each point is paired with a point from A), where each axis is the firing rate of a neuron. Data was centered for visualization purposes as CCA also centers data. The purple line indicates the axis in neural space chosen by CCA for panel D. C.) Original correlation between neuron 1 (panel B) and latent 1 (panel A). D.) First canonical variable pair from the data in panels A and B. The X and Y axes are now linear combinations of the latent and neural dimensions respectively. \relax }}{75}{figure.caption.147}\protected@file@percent }
\newlabel{fig:ccaIntuition}{{4.3}{75}{{\it Canonical Correlations in neural data} A.) Simulated stimulus data where points were randomly selected to span an arbitrary space. The red line indicates the axis chosen by CCA for panel D. B.) Neural state space of stimuli from panel A (each point is paired with a point from A), where each axis is the firing rate of a neuron. Data was centered for visualization purposes as CCA also centers data. The purple line indicates the axis in neural space chosen by CCA for panel D. C.) Original correlation between neuron 1 (panel B) and latent 1 (panel A). D.) First canonical variable pair from the data in panels A and B. The X and Y axes are now linear combinations of the latent and neural dimensions respectively. \relax }{figure.caption.147}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces {\it  Baseline-Corrected R values} The baseline-corrected r values for each canonical variable pair across brain region and algorithm. Baseline correction was calculated by subtracting out the distribution of r values calculated from randomly permuting predictors and calculating CCA 100 times. The number of significant CCA pairs was calculated using Rao's approximate F statistic.\relax }}{76}{figure.caption.148}\protected@file@percent }
\newlabel{fig:ccaR}{{4.4}{76}{{\it Baseline-Corrected R values} The baseline-corrected r values for each canonical variable pair across brain region and algorithm. Baseline correction was calculated by subtracting out the distribution of r values calculated from randomly permuting predictors and calculating CCA 100 times. The number of significant CCA pairs was calculated using Rao's approximate F statistic.\relax }{figure.caption.148}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces {\it  Linear Relationships in V1} A.) Top CCA pair for a PSO session in V1. Each point is one stimulus and color indicates the normalized $L^2$ norm of the population response vector to that image. B.) Same as panel A for a session optimized with the genetic algorithm. C.) Same as panels A\&B for a session in which no optimization was performed, and instead random images were shown. D-F.) Same as panels A-C except the color now indicates the order of stimuli in the session. G-I.) The GAN latent dimension that CCA found was most linearly related to neural activity for each algorithm. These dimensions correspond to the X-axes in panels A-F.\relax }}{77}{figure.caption.149}\protected@file@percent }
\newlabel{fig:cca1V1}{{4.5}{77}{{\it Linear Relationships in V1} A.) Top CCA pair for a PSO session in V1. Each point is one stimulus and color indicates the normalized $L^2$ norm of the population response vector to that image. B.) Same as panel A for a session optimized with the genetic algorithm. C.) Same as panels A\&B for a session in which no optimization was performed, and instead random images were shown. D-F.) Same as panels A-C except the color now indicates the order of stimuli in the session. G-I.) The GAN latent dimension that CCA found was most linearly related to neural activity for each algorithm. These dimensions correspond to the X-axes in panels A-F.\relax }{figure.caption.149}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces {\it  Linear Relationshipsin V4} A.) Top CCA pair for a PSO session in V4. Each point is one stimulus and color indicates the normalized $L^2$ norm of the population response vector to that image. B.) Same as panel A for a session optimized with the genetic algorithm. C.) Same as panels A\&B for a session in which no optimization was performed, and instead random images were shown. D-F.) Same as panels A-C except the color now indicates the order of stimuli in the session. G-I.) The GAN latent dimension that CCA found was most linearly related to neural activity for each algorithm. These dimensions correspond to the X-axes in panels A-F.\relax }}{78}{figure.caption.150}\protected@file@percent }
\newlabel{fig:cca1V4}{{4.6}{78}{{\it Linear Relationshipsin V4} A.) Top CCA pair for a PSO session in V4. Each point is one stimulus and color indicates the normalized $L^2$ norm of the population response vector to that image. B.) Same as panel A for a session optimized with the genetic algorithm. C.) Same as panels A\&B for a session in which no optimization was performed, and instead random images were shown. D-F.) Same as panels A-C except the color now indicates the order of stimuli in the session. G-I.) The GAN latent dimension that CCA found was most linearly related to neural activity for each algorithm. These dimensions correspond to the X-axes in panels A-F.\relax }{figure.caption.150}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces {\it  Projections onto CCA1}The value of projections onto Canonical variable pair 1 for each stimulus shown. PSO tends to pick one side of the latent space that it knows has strong optimization evaluations, whereas the genetic algorithm explores more.\relax }}{79}{figure.caption.151}\protected@file@percent }
\newlabel{fig:ccaProjections}{{4.7}{79}{{\it Projections onto CCA1}The value of projections onto Canonical variable pair 1 for each stimulus shown. PSO tends to pick one side of the latent space that it knows has strong optimization evaluations, whereas the genetic algorithm explores more.\relax }{figure.caption.151}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces {\it  DCA pair 1 in V1 across Algorithms} A.) Top DCA pair for a PSO session in V4. Each point is one stimulus and color indicates the normalized $L^2$ norm of the population response vector to that image. B.) Same as panel A for a session optimized with the genetic algorithm. C.) Same as panels A\&B for a session in which no optimization was performed, and instead random images were shown. D-F.) Same as panels A-C except the color now indicates the order of stimuli in the session. G-I.) The GAN latent dimension that DCA found was most strongly related to neural activity for each algorithm. These dimensions correspond to the X-axes in panels A-F.\relax }}{80}{figure.caption.152}\protected@file@percent }
\newlabel{fig:dca1V1}{{4.8}{80}{{\it DCA pair 1 in V1 across Algorithms} A.) Top DCA pair for a PSO session in V4. Each point is one stimulus and color indicates the normalized $L^2$ norm of the population response vector to that image. B.) Same as panel A for a session optimized with the genetic algorithm. C.) Same as panels A\&B for a session in which no optimization was performed, and instead random images were shown. D-F.) Same as panels A-C except the color now indicates the order of stimuli in the session. G-I.) The GAN latent dimension that DCA found was most strongly related to neural activity for each algorithm. These dimensions correspond to the X-axes in panels A-F.\relax }{figure.caption.152}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces {\it  DCA pair 1 in V4 across Algorithms} A.) Top DCA pair for a PSO session in V4. Each point is one stimulus and color indicates the normalized $L^2$ norm of the population response vector to that image. B.) Same as panel A for a session optimized with the genetic algorithm. C.) Same as panels A\&B for a session in which no optimization was performed, and instead random images were shown. D-F.) Same as panels A-C except the color now indicates the order of stimuli in the session. G-I.) The GAN latent dimension that DCA found was most strongly related to neural activity for each algorithm. These dimensions correspond to the X-axes in panels A-F.\relax }}{81}{figure.caption.153}\protected@file@percent }
\newlabel{fig:dca1V4}{{4.9}{81}{{\it DCA pair 1 in V4 across Algorithms} A.) Top DCA pair for a PSO session in V4. Each point is one stimulus and color indicates the normalized $L^2$ norm of the population response vector to that image. B.) Same as panel A for a session optimized with the genetic algorithm. C.) Same as panels A\&B for a session in which no optimization was performed, and instead random images were shown. D-F.) Same as panels A-C except the color now indicates the order of stimuli in the session. G-I.) The GAN latent dimension that DCA found was most strongly related to neural activity for each algorithm. These dimensions correspond to the X-axes in panels A-F.\relax }{figure.caption.153}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces {\it  Relative Linearity by Brain region} A.) Linearity of neural/stimulus relationships by DCA dimension pairs. Stimulus parameters used were the GAN latent variables. DCA dimensoin pairs are organized by descending distance covariance and relative linearity was calculated as described in \hyperref  [{methods:relativeLinearity}]{Methods}. Each line represents one session, and is colored according to brain area. B.) Same as panel A for pixel predictors.\relax }}{82}{figure.caption.154}\protected@file@percent }
\newlabel{fig:dcaLinearity}{{4.10}{82}{{\it Relative Linearity by Brain region} A.) Linearity of neural/stimulus relationships by DCA dimension pairs. Stimulus parameters used were the GAN latent variables. DCA dimensoin pairs are organized by descending distance covariance and relative linearity was calculated as described in \hyperref [{methods:relativeLinearity}]{Methods}. Each line represents one session, and is colored according to brain area. B.) Same as panel A for pixel predictors.\relax }{figure.caption.154}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Discussion}{83}{section.155}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Conclusion}{85}{section.156}\protected@file@percent }
\@setckpt{Chapters/Chapter_MultidimensionalFeatureTuning}{
\setcounter{page}{87}
\setcounter{equation}{7}
\setcounter{enumi}{4}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{5}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{10}
\setcounter{table}{0}
\setcounter{LT@tables}{2}
\setcounter{LT@chunks}{1}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{parentequation}{0}
\setcounter{su@anzahl}{0}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{132}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{0}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{50}
\setcounter{highnamepenalty}{50}
\setcounter{lownamepenalty}{25}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{blx@maxsection}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{1}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{AM@survey}{0}
\setcounter{supplementcounter}{0}
\setcounter{scratchcounter}{0}
\setcounter{section@level}{1}
\setcounter{Item}{19}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{30}
}
